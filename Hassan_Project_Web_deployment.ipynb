{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Connecting google Drive"
      ],
      "metadata": {
        "id": "d_rY2WW6454R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.flush_and_unmount()  # Unmount the drive first\n",
        "drive.mount('/content/drive')  # Remount Google Drive\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-N6bUfc7K4T",
        "outputId": "5b719b78-24ae-4e8a-a0ef-8905f7a5730e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive not mounted, so nothing to flush and unmount.\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dependencies"
      ],
      "metadata": {
        "id": "3i2lh_xTEWdT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy pandas mne tensorflow keras pyriemann\n",
        "!pip install -q streamlit\n",
        "!pip install joblib\n",
        "!npm install localtunnel"
      ],
      "metadata": {
        "id": "fozV9YM058c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c199148b-ea42-40a9-8d57-3307a67fd1f1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: mne in /usr/local/lib/python3.10/dist-packages (1.8.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.4.1)\n",
            "Requirement already satisfied: pyriemann in /usr/local/lib/python3.10/dist-packages (0.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mne) (3.1.4)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.10/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.10/dist-packages (from mne) (3.7.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mne) (24.1)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.10/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from mne) (1.13.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mne) (4.66.5)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.8.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.12.1)\n",
            "Requirement already satisfied: scikit-learn>=0.24 in /usr/local/lib/python3.10/dist-packages (from pyriemann) (1.3.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from pyriemann) (1.4.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->mne) (3.1.4)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (4.3.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24->pyriemann) (3.5.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mne) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (1.4.2)\n",
            "\u001b[K\u001b[?25h\n",
            "added 22 packages, and audited 23 packages in 2s\n",
            "\n",
            "3 packages are looking for funding\n",
            "  run `npm fund` for details\n",
            "\n",
            "2 \u001b[33m\u001b[1mmoderate\u001b[22m\u001b[39m severity vulnerabilities\n",
            "\n",
            "To address all issues, run:\n",
            "  npm audit fix\n",
            "\n",
            "Run `npm audit` for details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Development"
      ],
      "metadata": {
        "id": "przoOiVNmaMF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "import os\n",
        "import numpy as np\n",
        "import mne\n",
        "import xgboost as xgb\n",
        "from scipy.signal import butter, sosfiltfilt\n",
        "from io import BytesIO\n",
        "import requests\n",
        "import matplotlib.pyplot as plt\n",
        "import tempfile\n",
        "\n",
        "# Set page configuration\n",
        "st.set_page_config(page_title=\"EDF File Classifier\", layout=\"wide\")\n",
        "\n",
        "# Define utility functions for EDF processing and filtering\n",
        "def butter_bandpass_filter(data, lowcut, highcut, fs, order=2):\n",
        "    \"\"\"Bandpass filter for EEG data.\"\"\"\n",
        "    nyq = 0.5 * fs\n",
        "    low = lowcut / nyq\n",
        "    high = highcut / nyq\n",
        "    sos = butter(order, [low, high], analog=False, btype='band', output='sos')\n",
        "    return sosfiltfilt(sos, data)\n",
        "\n",
        "@st.cache_data\n",
        "def load_edf_data(file_path, channels):\n",
        "    \"\"\"Load EDF data and select specified channels.\"\"\"\n",
        "    raw = mne.io.read_raw_edf(file_path, preload=True, verbose=False)\n",
        "    available_channels = [ch for ch in channels if ch in raw.ch_names]\n",
        "    if not available_channels:\n",
        "        raise ValueError(\"None of the selected channels are available in the EDF file.\")\n",
        "    raw.pick_channels(available_channels)\n",
        "    data = raw.get_data()\n",
        "    fs = raw.info['sfreq']\n",
        "    return data, fs, raw\n",
        "\n",
        "def process_edf(data, fs, model, channels, lowcut, highcut, epoch_s, epoch_e):\n",
        "    \"\"\"Process EEG data and return model predictions.\"\"\"\n",
        "    filtered_data = butter_bandpass_filter(data, lowcut, highcut, fs)\n",
        "\n",
        "    epochs = mne.make_fixed_length_epochs(\n",
        "        mne.io.RawArray(filtered_data, mne.create_info(channels, fs, ch_types='eeg')),\n",
        "        duration=(epoch_e - epoch_s) / 1000, preload=True\n",
        "    ).get_data()\n",
        "\n",
        "    # Flatten the data for XGBoost\n",
        "    X_flat = epochs.reshape(epochs.shape[0], -1)\n",
        "\n",
        "    # Make predictions using the loaded model\n",
        "    dmatrix = xgb.DMatrix(X_flat)\n",
        "    predictions = model.predict(dmatrix)\n",
        "\n",
        "    # Take the mean prediction over all epochs and classify\n",
        "    avg_prediction = np.mean(predictions)\n",
        "    if avg_prediction > 0.5:\n",
        "        return \"Abnormal\", filtered_data\n",
        "    else:\n",
        "        return \"Normal\", filtered_data\n",
        "\n",
        "@st.cache_resource\n",
        "def load_model(model_file_path):\n",
        "    \"\"\"Load the pre-trained XGBoost model.\"\"\"\n",
        "    model = xgb.Booster()\n",
        "    model.load_model(model_file_path)\n",
        "    return model\n",
        "\n",
        "def get_file_from_google_drive(google_drive_link):\n",
        "    \"\"\"Download EDF file from Google Drive link and save to a temporary file.\"\"\"\n",
        "    try:\n",
        "        file_id = google_drive_link.split('/d/')[1].split('/')[0]\n",
        "    except IndexError:\n",
        "        st.error(\"Invalid Google Drive link format.\")\n",
        "        return None\n",
        "    download_url = f\"https://drive.google.com/uc?export=download&id={file_id}\"\n",
        "    response = requests.get(download_url)\n",
        "    if response.status_code == 200:\n",
        "        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.edf')\n",
        "        temp_file.write(response.content)\n",
        "        temp_file.close()\n",
        "        return temp_file.name\n",
        "    else:\n",
        "        st.error(\"Failed to download the file from Google Drive.\")\n",
        "        return None\n",
        "\n",
        "# Main application\n",
        "def main():\n",
        "    st.title(\"🧠 EDF File Classifier\")\n",
        "\n",
        "    # Sidebar for user inputs\n",
        "    st.sidebar.header(\"Select Model\")\n",
        "    model_options = {\n",
        "        \"Default XGBoost Model\": \"xgboost_model.bin\",\n",
        "        \"Custom Model Path\": None,  # Placeholder for custom model path\n",
        "    }\n",
        "    selected_model_name = st.sidebar.selectbox(\"Choose a model\", list(model_options.keys()))\n",
        "    custom_model_path = \"\"\n",
        "    if selected_model_name == \"Custom Model Path\":\n",
        "        custom_model_path = st.sidebar.text_input(\"Enter custom model path\", value=\"/content/drive/MyDrive/Alternative_Scalp_EEG_Dataset/model/xgboost_model.bin\")\n",
        "\n",
        "    if st.sidebar.button(\"Load Model\"):\n",
        "        if selected_model_name == \"Custom Model Path\":\n",
        "            model_file_path = custom_model_path\n",
        "        else:\n",
        "            model_file_path = model_options[selected_model_name]\n",
        "\n",
        "        try:\n",
        "            model = load_model(model_file_path)\n",
        "            st.session_state['model'] = model\n",
        "            st.session_state['model_file_path'] = model_file_path\n",
        "            st.sidebar.success(f\"Model loaded successfully from `{model_file_path}`.\")\n",
        "        except Exception as e:\n",
        "            st.sidebar.error(f\"Error loading model from `{model_file_path}`: {e}\")\n",
        "            st.session_state['model'] = None\n",
        "\n",
        "    if 'model' in st.session_state and st.session_state['model'] is not None:\n",
        "        model = st.session_state['model']\n",
        "        # Proceed with data input and processing\n",
        "        st.header(\"Data Processing\")\n",
        "\n",
        "        st.subheader(\"Upload EDF File or Provide Link\")\n",
        "        uploaded_file = st.file_uploader(\"Choose an EDF file\", type=[\"edf\"])\n",
        "        google_drive_link = st.text_input(\"Or enter Google Drive link of your EDF file\")\n",
        "\n",
        "        # Move Configuration to Sidebar\n",
        "        st.sidebar.header(\"Configuration\")\n",
        "        channels = st.sidebar.multiselect(\n",
        "            \"Select EEG Channels\",\n",
        "            options=['FP1', 'FP2', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4', 'O1', 'O2',\n",
        "                     'F7', 'F8', 'T3', 'T4', 'T5', 'T6', 'FZ', 'PZ', 'CZ', 'A1', 'A2'],\n",
        "            default=['FP1', 'FP2', 'F3', 'F4', 'C3', 'C4']\n",
        "        )\n",
        "        lowcut = st.sidebar.slider(\"Lowcut Frequency\", 0.1, 10.0, 1.0)\n",
        "        highcut = st.sidebar.slider(\"Highcut Frequency\", 30.0, 100.0, 40.0)\n",
        "        epoch_s = st.sidebar.number_input(\"Epoch Start (ms)\", value=0)\n",
        "        epoch_e = st.sidebar.number_input(\"Epoch End (ms)\", value=1300)\n",
        "\n",
        "        if (uploaded_file or google_drive_link):\n",
        "            if st.button(\"Enter\"):\n",
        "                # Proceed with data loading and processing\n",
        "                if uploaded_file:\n",
        "                    # Save uploaded file to a temporary file\n",
        "                    temp_edf_file = tempfile.NamedTemporaryFile(delete=False, suffix='.edf')\n",
        "                    temp_edf_file.write(uploaded_file.read())\n",
        "                    temp_edf_file.close()\n",
        "                    edf_file_path = temp_edf_file.name\n",
        "                    st.write(f\"Processing uploaded EDF file: `{uploaded_file.name}`\")\n",
        "                else:\n",
        "                    edf_file_path = get_file_from_google_drive(google_drive_link)\n",
        "                    if edf_file_path is None:\n",
        "                        return\n",
        "                    st.write(\"Processing EDF file from Google Drive link\")\n",
        "\n",
        "                # Load EDF data\n",
        "                data_load_state = st.text(\"Loading data...\")\n",
        "                try:\n",
        "                    data, fs, raw = load_edf_data(edf_file_path, channels)\n",
        "                    data_load_state.text(\"Data loaded successfully!\")\n",
        "                except Exception as e:\n",
        "                    st.error(f\"Error loading EDF data: {e}\")\n",
        "                    return\n",
        "\n",
        "                # Visualize Raw EEG Signals\n",
        "                st.subheader(\"EEG Signal Visualization\")\n",
        "                fig, ax = plt.subplots(figsize=(10, 4))\n",
        "                times = np.linspace(0, len(data[0]) / fs, num=len(data[0]))\n",
        "                for i in range(len(data)):\n",
        "                    ax.plot(times, data[i] + i * 50, label=channels[i])  # Offset for visibility\n",
        "                ax.set_xlabel('Time (s)')\n",
        "                ax.set_ylabel('Amplitude (µV)')\n",
        "                ax.set_title('Raw EEG Signals')\n",
        "                ax.legend(loc='upper right')\n",
        "                st.pyplot(fig)\n",
        "\n",
        "                # Run Prediction and Get Filtered Data\n",
        "                with st.spinner(\"Running Prediction...\"):\n",
        "                    try:\n",
        "                        result, filtered_data = process_edf(data, fs, model, channels, lowcut, highcut, epoch_s, epoch_e)\n",
        "                        st.subheader(\"Prediction Result\")\n",
        "                        st.write(f\"**Prediction:** {result}\")\n",
        "                        if result == \"Abnormal\":\n",
        "                            st.error(\"The EEG recording indicates an **Abnormal** condition.\")\n",
        "                        else:\n",
        "                            st.success(\"The EEG recording indicates a **Normal** condition.\")\n",
        "                    except Exception as e:\n",
        "                        st.error(f\"Error during prediction: {e}\")\n",
        "                        return\n",
        "\n",
        "                # Visualize Filtered EEG Signals\n",
        "                st.subheader(\"Filtered EEG Signal Visualization\")\n",
        "                fig_filtered, ax_filtered = plt.subplots(figsize=(10, 4))\n",
        "                for i in range(len(filtered_data)):\n",
        "                    ax_filtered.plot(times, filtered_data[i] + i * 50, label=channels[i])  # Offset for visibility\n",
        "                ax_filtered.set_xlabel('Time (s)')\n",
        "                ax_filtered.set_ylabel('Amplitude (µV)')\n",
        "                ax_filtered.set_title('Filtered EEG Signals')\n",
        "                ax_filtered.legend(loc='upper right')\n",
        "                st.pyplot(fig_filtered)\n",
        "\n",
        "                # Clean up temporary files\n",
        "                if uploaded_file:\n",
        "                    os.unlink(edf_file_path)\n",
        "                elif google_drive_link:\n",
        "                    os.unlink(edf_file_path)\n",
        "            else:\n",
        "                st.info(\"Click 'Enter' to load and process the EDF file.\")\n",
        "        else:\n",
        "            st.warning(\"Please upload an EDF file or provide a Google Drive link to proceed.\")\n",
        "    else:\n",
        "        st.warning(\"Please load a model to proceed.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "W1vAPOFWN-7v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80d9dcd3-25ca-4893-c820-16210577774c"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deployment"
      ],
      "metadata": {
        "id": "4n4IfNodOEyi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py &>/content/logs.txt &"
      ],
      "metadata": {
        "id": "UlbX3oE9ehnd"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbSTxNszml98",
        "outputId": "e101068e-0fe2-4a6b-a0df-fd9e6fe5d3c1"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "your url is: https://vast-friends-call.loca.lt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "import os\n",
        "import numpy as np\n",
        "import mne\n",
        "import xgboost as xgb\n",
        "from scipy.signal import butter, sosfiltfilt\n",
        "from io import BytesIO\n",
        "import requests\n",
        "import matplotlib.pyplot as plt\n",
        "import tempfile\n",
        "\n",
        "# Set page configuration\n",
        "st.set_page_config(page_title=\"EDF File Classifier\", layout=\"wide\")\n",
        "\n",
        "# Define utility functions for EDF processing and filtering\n",
        "def butter_bandpass_filter(data, lowcut, highcut, fs, order=2):\n",
        "    \"\"\"Bandpass filter for EEG data.\"\"\"\n",
        "    nyq = 0.5 * fs\n",
        "    low = lowcut / nyq\n",
        "    high = highcut / nyq\n",
        "    sos = butter(order, [low, high], analog=False, btype='band', output='sos')\n",
        "    return sosfiltfilt(sos, data)\n",
        "\n",
        "@st.cache_data\n",
        "def load_edf_data(file_path, channels):\n",
        "    \"\"\"Load EDF data and select specified channels.\"\"\"\n",
        "    raw = mne.io.read_raw_edf(file_path, preload=True, verbose=False)\n",
        "    available_channels = [ch for ch in channels if ch in raw.ch_names]\n",
        "    if not available_channels:\n",
        "        raise ValueError(\"None of the selected channels are available in the EDF file.\")\n",
        "    raw.pick_channels(available_channels)\n",
        "    data = raw.get_data()\n",
        "    fs = raw.info['sfreq']\n",
        "    return data, fs, raw\n",
        "\n",
        "def process_edf(data, fs, model, channels, lowcut, highcut, epoch_s, epoch_e):\n",
        "    \"\"\"Process EEG data and return model predictions.\"\"\"\n",
        "    filtered_data = butter_bandpass_filter(data, lowcut, highcut, fs)\n",
        "\n",
        "    epochs = mne.make_fixed_length_epochs(\n",
        "        mne.io.RawArray(filtered_data, mne.create_info(channels, fs, ch_types='eeg')),\n",
        "        duration=(epoch_e - epoch_s) / 1000, preload=True\n",
        "    ).get_data()\n",
        "\n",
        "    # Flatten the data for XGBoost\n",
        "    X_flat = epochs.reshape(epochs.shape[0], -1)\n",
        "\n",
        "    # Make predictions using the loaded model\n",
        "    dmatrix = xgb.DMatrix(X_flat)\n",
        "    predictions = model.predict(dmatrix)\n",
        "\n",
        "    # Take the mean prediction over all epochs and classify\n",
        "    avg_prediction = np.mean(predictions)\n",
        "    if avg_prediction > 0.5:\n",
        "        return \"Abnormal\", filtered_data\n",
        "    else:\n",
        "        return \"Normal\", filtered_data\n",
        "\n",
        "@st.cache_resource\n",
        "def load_model(model_file_path):\n",
        "    \"\"\"Load the pre-trained XGBoost model.\"\"\"\n",
        "    model = xgb.Booster()\n",
        "    model.load_model(model_file_path)\n",
        "    return model\n",
        "\n",
        "def get_file_from_google_drive(google_drive_link):\n",
        "    \"\"\"Download EDF file from Google Drive link and save to a temporary file.\"\"\"\n",
        "    try:\n",
        "        file_id = google_drive_link.split('/d/')[1].split('/')[0]\n",
        "    except IndexError:\n",
        "        st.error(\"Invalid Google Drive link format.\")\n",
        "        return None\n",
        "    download_url = f\"https://drive.google.com/uc?export=download&id={file_id}\"\n",
        "    response = requests.get(download_url)\n",
        "    if response.status_code == 200:\n",
        "        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.edf')\n",
        "        temp_file.write(response.content)\n",
        "        temp_file.close()\n",
        "        return temp_file.name\n",
        "    else:\n",
        "        st.error(\"Failed to download the file from Google Drive.\")\n",
        "        return None\n",
        "\n",
        "# Main application\n",
        "def main():\n",
        "    st.title(\"🧠 EDF File Classifier\")\n",
        "\n",
        "    # Sidebar for user inputs\n",
        "    st.sidebar.header(\"Select Model\")\n",
        "    model_options = {\n",
        "        \"Default XGBoost Model\": \"xgboost_model.bin\",\n",
        "        \"Custom Model Path\": None,  # Placeholder for custom model path\n",
        "    }\n",
        "    selected_model_name = st.sidebar.selectbox(\"Choose a model\", list(model_options.keys()))\n",
        "    custom_model_path = \"\"\n",
        "    if selected_model_name == \"Custom Model Path\":\n",
        "        custom_model_path = st.sidebar.text_input(\"Enter custom model path\", value=\"/content/drive/MyDrive/Alternative_Scalp_EEG_Dataset/model/xgboost_model.bin\")\n",
        "\n",
        "    if st.sidebar.button(\"Load Model\"):\n",
        "        if selected_model_name == \"Custom Model Path\":\n",
        "            model_file_path = custom_model_path\n",
        "        else:\n",
        "            model_file_path = model_options[selected_model_name]\n",
        "\n",
        "        try:\n",
        "            model = load_model(model_file_path)\n",
        "            st.session_state['model'] = model\n",
        "            st.session_state['model_file_path'] = model_file_path\n",
        "            st.sidebar.success(f\"Model loaded successfully from `{model_file_path}`.\")\n",
        "        except Exception as e:\n",
        "            st.sidebar.error(f\"Error loading model from `{model_file_path}`: {e}\")\n",
        "            st.session_state['model'] = None\n",
        "\n",
        "    if 'model' in st.session_state and st.session_state['model'] is not None:\n",
        "        model = st.session_state['model']\n",
        "        # Proceed with data input and processing\n",
        "        st.header(\"Data Processing\")\n",
        "\n",
        "        st.subheader(\"Upload EDF File or Provide Link\")\n",
        "        uploaded_file = st.file_uploader(\"Choose an EDF file\", type=[\"edf\"])\n",
        "        google_drive_link = st.text_input(\"Or enter Google Drive link of your EDF file\")\n",
        "\n",
        "        # Move Configuration to Sidebar\n",
        "        st.sidebar.header(\"Configuration\")\n",
        "        channels = st.sidebar.multiselect(\n",
        "            \"Select EEG Channels\",\n",
        "            options=['FP1', 'FP2', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4', 'O1', 'O2',\n",
        "                     'F7', 'F8', 'T3', 'T4', 'T5', 'T6', 'FZ', 'PZ', 'CZ', 'A1', 'A2'],\n",
        "            default=['FP1', 'FP2', 'F3', 'F4', 'C3', 'C4']\n",
        "        )\n",
        "        lowcut = st.sidebar.slider(\"Lowcut Frequency\", 0.1, 10.0, 1.0)\n",
        "        highcut = st.sidebar.slider(\"Highcut Frequency\", 30.0, 100.0, 40.0)\n",
        "        epoch_s = st.sidebar.number_input(\"Epoch Start (ms)\", value=0)\n",
        "        epoch_e = st.sidebar.number_input(\"Epoch End (ms)\", value=1300)\n",
        "\n",
        "        if (uploaded_file or google_drive_link):\n",
        "            if st.button(\"Enter\"):\n",
        "                # Proceed with data loading and processing\n",
        "                if uploaded_file:\n",
        "                    # Save uploaded file to a temporary file\n",
        "                    temp_edf_file = tempfile.NamedTemporaryFile(delete=False, suffix='.edf')\n",
        "                    temp_edf_file.write(uploaded_file.read())\n",
        "                    temp_edf_file.close()\n",
        "                    edf_file_path = temp_edf_file.name\n",
        "                    st.write(f\"Processing uploaded EDF file: `{uploaded_file.name}`\")\n",
        "                else:\n",
        "                    edf_file_path = get_file_from_google_drive(google_drive_link)\n",
        "                    if edf_file_path is None:\n",
        "                        return\n",
        "                    st.write(\"Processing EDF file from Google Drive link\")\n",
        "\n",
        "                # Load EDF data\n",
        "                data_load_state = st.text(\"Loading data...\")\n",
        "                try:\n",
        "                    data, fs, raw = load_edf_data(edf_file_path, channels)\n",
        "                    data_load_state.text(\"Data loaded successfully!\")\n",
        "                except Exception as e:\n",
        "                    st.error(f\"Error loading EDF data: {e}\")\n",
        "                    return\n",
        "\n",
        "                # Visualize Raw EEG Signals\n",
        "                st.subheader(\"EEG Signal Visualization\")\n",
        "                fig, ax = plt.subplots(figsize=(10, 4))\n",
        "                times = np.linspace(0, len(data[0]) / fs, num=len(data[0]))\n",
        "                for i in range(len(data)):\n",
        "                    ax.plot(times, data[i] + i * 50, label=channels[i])  # Offset for visibility\n",
        "                ax.set_xlabel('Time (s)')\n",
        "                ax.set_ylabel('Amplitude (µV)')\n",
        "                ax.set_title('Raw EEG Signals')\n",
        "                ax.legend(loc='upper right')\n",
        "                st.pyplot(fig)\n",
        "\n",
        "                # Run Prediction and Get Filtered Data\n",
        "                with st.spinner(\"Running Prediction...\"):\n",
        "                    try:\n",
        "                        result, filtered_data = process_edf(data, fs, model, channels, lowcut, highcut, epoch_s, epoch_e)\n",
        "                        st.subheader(\"Prediction Result\")\n",
        "                        st.write(f\"**Prediction:** {result}\")\n",
        "                        if result == \"Abnormal\":\n",
        "                            st.error(\"The EEG recording indicates an **Abnormal** condition.\")\n",
        "                        else:\n",
        "                            st.success(\"The EEG recording indicates a **Normal** condition.\")\n",
        "                    except Exception as e:\n",
        "                        st.error(f\"Error during prediction: {e}\")\n",
        "                        return\n",
        "\n",
        "                # Visualize Filtered EEG Signals\n",
        "                st.subheader(\"Filtered EEG Signal Visualization\")\n",
        "                fig_filtered, ax_filtered = plt.subplots(figsize=(10, 4))\n",
        "                for i in range(len(filtered_data)):\n",
        "                    ax_filtered.plot(times, filtered_data[i] + i * 50, label=channels[i])  # Offset for visibility\n",
        "                ax_filtered.set_xlabel('Time (s)')\n",
        "                ax_filtered.set_ylabel('Amplitude (µV)')\n",
        "                ax_filtered.set_title('Filtered EEG Signals')\n",
        "                ax_filtered.legend(loc='upper right')\n",
        "                st.pyplot(fig_filtered)\n",
        "\n",
        "                # Clean up temporary files\n",
        "                if uploaded_file:\n",
        "                    os.unlink(edf_file_path)\n",
        "                elif google_drive_link:\n",
        "                    os.unlink(edf_file_path)\n",
        "            else:\n",
        "                st.info(\"Click 'Enter' to load and process the EDF file.\")\n",
        "        else:\n",
        "            st.warning(\"Please upload an EDF file or provide a Google Drive link to proceed.\")\n",
        "    else:\n",
        "        st.warning(\"Please load a model to proceed.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "3pBTf5LKpE2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "CkYY6OTMvxvc"
      }
    }
  ]
}